# -*- coding: utf-8 -*-
"""Phase2ML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/129VDh_HbcigN-g-3Vm9hMjgRhcQ5-Xsr

# Imports & Read Data
"""


# Imports
import sklearn
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn import linear_model
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import OneHotEncoder
from category_encoders import  LeaveOneOutEncoder as l1o
from sklearn.preprocessing import MultiLabelBinarizer
from pandas.io.formats.style_render import Subset
from sklearn import tree
from sklearn.metrics import confusion_matrix
from sklearn.metrics import multilabel_confusion_matrix
import joblib
from sklearn import svm
from sklearn.multiclass import OneVsRestClassifier,OneVsOneClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
import time

# Read data
#data1 = pd.read_csv('player-tas-regression-test.csv')
data = pd.read_csv('player-value-prediction.csv')
print(f"Data has {data.shape[0]} Rows and {data.shape[1]} Features")
pd.set_option('display.min_rows',500)

"""# Preprocessing

## Missing Values
"""

def dropMissingValues(data):
  data.dropna(axis=0,how='any',inplace=True,subset=['club_team','club_rating','contract_end_year'])
  data.dropna(axis=0,how='any', subset=['value'],inplace=True)

# Fill missing values
ToSaveList={}
def fillMissingValues(x):
  ToSaveList['nationality']=x.nationality.mode()[0]
  x.nationality.fillna(x.nationality.mode()[0],inplace=True)
  ToSaveList['wage']=x.wage.mean()
  x.wage.fillna(x.wage.mean(),inplace=True)
  ToSaveList['release_clause_euro']=x.release_clause_euro.mean()
  x.release_clause_euro.fillna(x.release_clause_euro.mean(),inplace=True)
  ToSaveList['club_join_date']=x.club_join_date.mode()[0]
  x.club_join_date.fillna(x.club_join_date.mode()[0],inplace=True) 
  ToSaveList['club_team']=x.club_team.mode()[0]
  x.club_team.fillna(x.club_team.mode()[0],inplace=True)
  ToSaveList['national_rating']=x.national_rating.mean()
  x.national_rating.fillna(x.national_rating.mean(),inplace=True)
  ToSaveList['national_jersey_number']=x.national_jersey_number.mode()[0]
  x.national_jersey_number.fillna(x.national_jersey_number.mode()[0],inplace=True)

def handleMissingValues(data):
  dropMissingValues(data)
  fillMissingValues(data)

"""## Feature Engineering"""

def applyFeatureEngineering(x):
  # Split "work_rate" into "work_rate_attack" and "work_rate_defense"
  x[['work_rate_attack','work_rate_defense']]=x['work_rate'].str.split('/ ',1,expand=True)
  x.drop('work_rate',axis=1,inplace=True)

  # Extract dates from columns "club_join_date" & "contract_end_year

  # Column "club_join_date"
  x['club_join_date']=x['club_join_date'].str.split('/',2,expand=True)[2]#13/5/2001 
  x=x.astype({'club_join_date':'float'})
  x['birth_date']=x['birth_date'].str.split('/',2,expand=True)[2]#13/5/2001 
  x=x.astype({'birth_date':'float'})
  # Column "contract_end_year"
  
  x=x.astype({'contract_end_year':'str'})
  x['contract_end_year']=x['contract_end_year'].apply(lambda z: '20'+z.split('-',2)[2] if (len(z)>4)else z)
  x=x.astype({'contract_end_year':'float'})
  print(x['contract_end_year'])
  # Loops over all position columns and adds the bonuses to the original score & fills nulls with mean of result
  # Ex: 62+2 --> 64
  # Assume mean = 61: null --> 61
  for i in range(x.columns.get_loc('LS'),x.columns.get_loc('RB')+1):
    x=x.astype({x.columns[i]:'str'})
    x[x.columns[i]]=x[x.columns[i]].apply(lambda z: int(z.split('+',2)[0])+int(z.split('+',2)[1])if(z!='nan'and len(z)>2)else z)
    x=x.astype({x.columns[i]:'float'})
    ToSaveList[x.columns[i]]=x[x.columns[i]].mean()
    x[x.columns[i]].fillna(x[x.columns[i]].mean(),inplace=True)
    # Question: Why is the column casted to int then to float?
    x=x.astype({x.columns[i]:'int'})
    x=x.astype({x.columns[i]:'float'})
  return x

"""## Encoding"""

# Helper Functions
def Feature_Encoder(X,cols):
    for c in cols:
        lbl = LabelEncoder()
        lbl.fit(list(X[c].values))
        X[c] = lbl.transform(list(X[c].values))
        #joblib.dump(lbl, c+"LabelEncoder.pkl")
    return X

def encode_club_position(df):
    if (df['club_position'] == 'GK'):
        return 'GK'
    elif ((df['club_position'] == 'RB') | (df['club_position'] == 'LB') | (df['club_position'] == 'CB') | (df['club_position'] == 'LCB') | (df['club_position'] == 'RCB') | (df['club_position'] == 'RWB') | (df['club_position'] == 'LWB') ):
        return 'DF'
    elif ((df['club_position'] == 'LDM') | (df['club_position'] == 'CDM') | (df['club_position'] == 'RDM')):
        return 'DM'
    elif ((df['club_position'] == 'LM') | (df['club_position'] == 'LCM') | (df['club_position'] == 'CM') | (df['club_position'] == 'RCM') | (df['club_position'] == 'RM')):
        return 'MF'
    elif ((df['club_position'] == 'LAM') | (df['club_position'] == 'CAM') | (df['club_position'] == 'RAM') | (df['club_position'] == 'LW') | (df['club_position'] == 'RW')):
        return 'AM'
    elif ((df['club_position'] == 'RS') | (df['club_position'] == 'ST') | (df['club_position'] == 'LS') | (df['club_position'] == 'CF') | (df['club_position'] == 'LF') | (df['club_position'] == 'RF')):
        return 'ST'
    else:
        return df.club_position

def encode_positions(position):
   position = position[0]
   if (position == 'GK'):
        return 'pos_GK'
   elif ((position == 'RB') | (position == 'LB') | (position == 'CB') | (position == 'LCB') | (position == 'RCB') | (position == 'RWB') | (position == 'LWB') ):
      return 'pos_DF'
   elif ((position == 'LDM') | (position == 'CDM') | (position == 'RDM')):
      return 'pos_DM'
   elif ((position == 'LM') | (position == 'LCM') | (position == 'CM') | (position == 'RCM') | (position == 'RM')):
      return 'pos_MF'
   elif ((position == 'LAM') | (position == 'CAM') | (position == 'RAM') | (position == 'LW') | (position == 'RW')):
      return 'pos_AM'
   elif ((position == 'RS') | (position == 'ST') | (position == 'LS') | (position == 'CF') | (position == 'LF') | (position == 'RF')):
       return 'pos_ST'
   else:
       return 'pos_'+position

def applyLabelEncoding(x):
  ## columns "work_rate_attack" & "work_rate_defense"
  x["work_rate_attack"]= np.where(x["work_rate_attack"]=="High",2,np.where(x["work_rate_attack"]=="Low",0,1))
  x["work_rate_defense"]= np.where(x["work_rate_defense"]=="High",2,np.where(x["work_rate_defense"]=="Low",0,1))

  ## columns "club_position" & "body_type" & "preferred_foot" 
  x=Feature_Encoder(x,['body_type','preferred_foot'])
  x['preferred_foot_right']=x['preferred_foot']#have no order()
  x.drop('preferred_foot',axis=1,inplace=True)
  x=Feature_Encoder(x,["national_team_position"])

  ## column "positions"
  first_pos = x['positions'].str.split(',', expand=True)[0]
  first_pos = pd.DataFrame(first_pos)
  x['positions'] = first_pos.apply(encode_positions, axis=1)
  x = Feature_Encoder(x, ['positions'])


  # //////
  l1 = LabelEncoder()
  l1.fit(x['name'])
  
  x['name'] = l1.transform(x['name'])
  l1.fit(x['full_name'])
  x['full_name'] = l1.transform(x['full_name'])
  return x

def applyLeaveOneOutEncoding(x,y):
  ## Columns "nationality" & "club_team" & "positions" using leave one out encoding
  leave1out=l1o()
  y.index=x.index
  # QUESTION: Why club_team twice?
  # x['club_team']=leave1out.fit_transform(x['club_team'],y)
  x['club_team']=leave1out.fit_transform(x['club_team'],y)
  x['nationality']=leave1out.fit_transform(x['nationality'],y)
  # Column "club_position"
  #joblib.dump(leave1out, "nationalityleave1out.pkl")
  x['club_position'] = x.apply(encode_club_position, axis = 1)
  x['club_position']=leave1out.fit_transform(x['club_position'],y)
  #joblib.dump(leave1out, "club_positionleave1out.pkl")
  return x

def applyOneHotEncoder(x):
  x["Speed Dribbler"]=np.where(x.traits=='Speed Dribbler (CPU AI Only)',1,0)
  x["Injury Prone"]=np.where(x.traits=='Injury Prone',1,0)
  x["Technical Dribbler"]=np.where(x.traits=='Technical Dribbler (CPU AI Only)',1,0)
  x["Dives Into Tackles"]=np.where(x.traits=='Dives Into Tackles (CPU AI Only)',1,0)
  x["Unkown"]=np.where(x.traits==None,1,0)
  x.national_team=np.where(x.national_team==None,0,1)
  x.national_team=np.where(x.national_team_position==None,0,x.national_team_position)
  x["#Speedstar"]=np.where(x.tags=='#Speedstar',1,0)
  x["#Poacher"]=np.where(x.tags=='#Poacher',1,0)
  x["#Strength"]=np.where(x.tags=='#Strength',1,0)
  x["Unkown_tags"]=np.where(x.tags==None,1,0)
  return x

"""## Feature Selection"""

# Drop highly correlated features
def dropColumns(x,cols):
  x.drop(cols, axis=1, inplace=True)

"""##FanctionsCall"""

handleMissingValues(data)
data=applyFeatureEngineering(data)
data=applyLabelEncoding(data)
y=data['value']
#y= np.where(y=="S",5,np.where(y=="A",4,np.where(y=="B",3,np.where(y=="C",2,1))))
y=pd.DataFrame(y)
data=applyLeaveOneOutEncoding(data,y)
data=applyOneHotEncoder(data) 

to_drop = ['RCB', 'CB', 'LCB', 'LB', 'RWB', 'RDM', 'CDM', 'LDM', 'LWB', 'LS', 'ST', 'RS', 'LW', 'LF', 'CF', 'RF', 'RW', 'LAM', 'CAM', 'RAM','LM','LCM','CM','RM','GK_diving', 'GK_handling', 'GK_positioning', 'GK_reflexes', 'standing_tackle','sliding_tackle','ball_control','positioning','acceleration','Speed Dribbler','Injury Prone','Technical Dribbler','Dives Into Tackles','Unkown','#Speedstar','#Poacher','#Strength',
           'Unkown_tags','name','full_name','birth_date','id','height_cm','club_jersey_number','club_team' ,'tags','traits','national_team',
 'national_rating', 'national_team_position', 'national_jersey_number','value']
dropColumns(data,to_drop)
x=data

"""# Visualization"""

tmp = pd.concat((x, y), axis=1)

corr =tmp.corr().abs()
plt.figure(figsize=(70,70))
sns.heatmap(corr, annot=True)
plt.show()

# Print highly correlated features without repetition

#the matrix is symmetric so we need to extract upper triangle matrix without diagonal (k = 1)
#and sort correlation values from higher to lower
# sol = (corr.where(np.triu(np.ones(corr.shape), k=1).astype(np.bool))
#                   .stack()
#                   .sort_values(ascending=False))

"""# Models

## Regression Models
"""

# Split data
###

###
start_time = time.time()
#best_test_error =  432896306883.1006
#best_test_error =  1527621844424.3254
print(x.columns,y.columns)
xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=633)
# Linear regresion model (Degree = 1, No regularization)
lr=linear_model.LinearRegression()
lr.fit(xtrain,ytrain)

# Predictions
#
print(x.columns)
print("--- %s seconds ---" , (time.time() - start_time))

#print('score',lr.score(,ytest)*100)
#print('Train MSE: ',metrics.mean_squared_error(ytrain,ytp))
#print('Test MSE: ',metrics.mean_squared_error(ytest,ypred))
#print('Best test MSE: ', best_test_error)
#print('Train R2 score: ', metrics.r2_score(ytrain,ytp))
#print('Test R2 score: ', metrics.r2_score(ytest,ypred))
#print('Test R2 score: ', predicted_r2(ytest,ypred,xtest))

#Save model
joblib.dump(lr, "lin.pkl")


# Linear regresion model (Degree = 2, No regularization)
start_time = time.time()
xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=453,shuffle=True)
m=PolynomialFeatures(degree=2)
xp=m.fit_transform(x)
poly_model = linear_model.LinearRegression()
poly_model.fit(xp, y)
y_train_predicted = poly_model.predict(xp)
ypred=poly_model.predict(m.transform(xtest))
# predicting on test data-set
# Question: Why fit_transform and not transform?
prediction = poly_model.predict(m.fit_transform(xtest))
#TimeList.append(time.time() - start_time)
#print('Best test MSE: ', best_test_error)
#print('score',poly_model.score(m.transform(xtest),ytest)*100)
#$print('Train MSE: ',metrics.mean_squared_error(ytrain,y_train_predicted))
#print('Test MSE: ',metrics.mean_squared_error(ytest,prediction))
#print('Train R2 score: ', metrics.r2_score(ytrain,y_train_predicted))
#print('Test R2 score: ', metrics.r2_score(ytest,prediction))
#print('Test R2 score: ', predicted_r2(ytest,prediction,xtest))

#Save model
joblib.dump(poly_model, "poly_regerssion[degree=2_random_state=453].pkl")
joblib.dump(m, "22PolynomialFeatures(degree=2).pkl")

"""## Classification Models"""

# Decision Tree
ModelList=[]
TimeList=[]
xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=453,shuffle=True)
clf = tree.DecisionTreeClassifier(random_state=1334,max_depth=29)
clf.fit(x , y)

ypred=clf.predict(xtest)

# Accuracy
print("Train score",clf.score(xtrain,ytrain)*100)
start_time = time.time()
print("test",clf.score(xtest,ytest)*100)
TimeList.append(time.time() - start_time)
print("fitting time --- %s seconds ---" , (time.time() - start_time))
ModelList.append('DecisionTree')

print(metrics.f1_score(ytest,ypred, pos_label='positive',average='micro'))
#Confusion Matrixes
print(multilabel_confusion_matrix(ytest,ypred))
confusion_matrix(ytest,ypred)
# Save model
#joblib.dump(clf, "tree_random_state=1334.pkl")

# SVM
C = 1.3

 # SVM regularization parameter
svc = svm.SVC(kernel='rbf', C=C)
s=OneVsOneClassifier(svc).fit(x, y)
print('training',' ', s.score(xtrain,ytrain))
start_time = time.time()
print('testing',' ',s.score(xtest,ytest))
# print("fitting time --- %s seconds ---" , (time.time() - start_time))
TimeList.append(time.time() - start_time)
ModelList.append('SVM')

# accuracy = np.mean(predictions == ytest)
# print('Testing accuracy :', accuracy)
# print('-----------------------------')
# print(s.score(xtest,ytest))
# Save model rbf_oneVSone_C=1.3
#joblib.dump(s, "SVM(linear).pkl")

# Logistic Regression
from sklearn.linear_model import LogisticRegression
logistic=LogisticRegression()
s=OneVsOneClassifier(logistic).fit(x, y)
print('Training ',s.score(xtrain,ytrain))
start_time = time.time()
print('Testing',s.score(xtest,ytest))
print("--- %s seconds ---" , (time.time() - start_time))
TimeList.append(time.time() - start_time)
ModelList.append('Logistic Regression')

# Save model
#joblib.dump(s, "Logistic.pkl")

"""##Random Forest"""

clf=RandomForestClassifier(max_depth=16,random_state=49,max_features=4,criterion='entropy',n_estimators=700,min_samples_split=3,
    ).fit(x,y)

print('training',' ',clf.score(xtrain,ytrain))
start_time = time.time()
print('testing',' ',clf.score(xtest,ytest))
TimeList.append(time.time() - start_time)
print("fitting time --- %s seconds ---" , (time.time() - start_time))
ModelList.append('Random Forest')
#joblib.dump(clf, "RandomForest(max_depth=16,random_state=49,max_features=4,criterion='entropy',n_estimators=700,min_samples_split=3,).pkl")

"""# Unformatted Code

##Plotting Data
"""
#
# print(ModelList)
# print(TimeList)
# #sns.countplot(x=ModelList,hue=TimeList)
# data_dict = {'DecisionTree':TimeList[0], 'Logistic Regression':TimeList[2], 'Random Forest':TimeList[3], 'SVM':TimeList[1]}
# models = list(data_dict.keys())
# times = list(data_dict.values())
# fig = plt.figure(figsize = (10, 10))
# #  Bar plot
# plt.bar(models, times, color ='green',
#         width = 0.5)
# plt.xlabel("Models")
# plt.ylabel("test time")
#
# plt.show()
#
# # -*- coding: utf-8 -*-
#
#
# # from google.colab import drive
# # drive.mount('/content/drive/')
# # !pip install category_encoders
# import sklearn
# import numpy as np
# import pandas as pd
# import seaborn as sns
# import matplotlib.pyplot as plt
# from sklearn import linear_model
# from sklearn import metrics
# from sklearn.model_selection import train_test_split
# from sklearn.preprocessing import PolynomialFeatures
# from sklearn.preprocessing import LabelEncoder
# from sklearn.preprocessing import MinMaxScaler
# from sklearn.preprocessing import OneHotEncoder
# from category_encoders import  LeaveOneOutEncoder as l1o
# from sklearn.preprocessing import MultiLabelBinarizer
# from pandas.io.formats.style_render import Subset
#
# data = pd.read_csv('player-classification.csv')
# pd.set_option('display.min_rows',500)
# print(f"Data has {data.shape[0]} Rows and {data.shape[1]} Features")
#
# """# **Preprocessing**
#
# ## Helper Functions Definitions
# """
#
# def Feature_Encoder(X,cols):
#     for c in cols:
#         lbl = LabelEncoder()
#         lbl.fit(list(X[c].values))
#         X[c] = lbl.transform(list(X[c].values))
#     return X
#
# """## Missing Values
#
# ### Drop rows & columns containing missing values
# """
#
# # Columns dropped ['national_team', 'national_rating', 'national_team_position', 'national_jersey_number', 'tags', 'traits']
# data.drop(axis=1,inplace=True,columns=['height_cm'])#### club_team may be droped
# # ~300 rows dropped
# data.dropna(axis=0,how='any',inplace=True,subset=['club_team','club_rating','contract_end_year'])
# data.dropna(axis=1,how='any',inplace=True,thresh=12000)#null more than 2000
# data.dropna(axis=0,how='any', subset=['PlayerLevel'],inplace=True)
# # Columns dropped ['id', 'name', 'full_name', 'birth_date']
# data=data.iloc[:,4:91]
#
# # Columns dropped ['id', 'name', 'full_name', 'birth_date']
# x=data.drop('PlayerLevel', axis = 1)
# y=data['PlayerLevel']
# y=pd.DataFrame(y)
# # print('x shape',x.shape)
# # print('y shape',y.shape)
# # print(y)
#
# # print(x.columns)
# # print(x.isnull().sum())
# x=data.drop('PlayerLevel', axis = 1)
#
# y= np.where(y=="S",5,np.where(y=="A",4,np.where(y=="B",3,np.where(y=="C",2,1))))
# y=pd.DataFrame(y)
# """## Feature Engineering
#
# ### Split column "work_rate" into two columns "work_rate_attack" & "work_rate_defense"
# """
#
# x[['work_rate_attack','work_rate_defense']]=x['work_rate'].str.split('/ ',1,expand=True)
# x.drop('work_rate',axis=1,inplace=True)
#
# #"""### Extract dates from columns "club_join_date" & "contract_end_year""""
#
# # Column "club_join_date"
# x['club_join_date']=x['club_join_date'].str.split('/',2,expand=True)[2]#13/5/2001
# x=x.astype({'club_join_date':'float'})
# # Column "contract_end_year"
# x=x.astype({'contract_end_year':'str'})
# x['contract_end_year']=x['contract_end_year'].apply(lambda z: '20'+z.split('-',2)[2] if (len(z)>4)else z)
# x=x.astype({'contract_end_year':'float'})
#
# """## Encoding
#
# ### Encode columns 'work_rate_attack' & 'work_rate_defense' using label encoding
# """
#
# x["work_rate_attack"]= np.where(x["work_rate_attack"]=="High",2,np.where(x["work_rate_attack"]=="Low",0,1))
# x["work_rate_defense"]= np.where(x["work_rate_defense"]=="High",2,np.where(x["work_rate_defense"]=="Low",0,1))
#
# """### Encode columns "club_position" & "body_type" & "preferred_foot" using label encoding"""
#
# #print(x.club_position.unique())
# x=Feature_Encoder(x,['body_type','preferred_foot'])
# x['preferred_foot_right']=x['preferred_foot']#have no order()
# x.drop('preferred_foot',axis=1,inplace=True)
#
# """### Encode columns "nationality" & "club_team" & "positions" using leave one out encoding"""
#
# leave1out=l1o()
# y.index=x.index
# x['club_team']=leave1out.fit_transform(x['club_team'],y)
# x[['nationality','club_team']]=leave1out.fit_transform(x[['nationality','club_team']],y)
#
# """# **Old format code**"""
#
# def encode_club_position(df):
#     if (df['club_position'] == 'GK'):
#         return 'GK'
#     elif ((df['club_position'] == 'RB') | (df['club_position'] == 'LB') | (df['club_position'] == 'CB') | (df['club_position'] == 'LCB') | (df['club_position'] == 'RCB') | (df['club_position'] == 'RWB') | (df['club_position'] == 'LWB') ):
#         return 'DF'
#     elif ((df['club_position'] == 'LDM') | (df['club_position'] == 'CDM') | (df['club_position'] == 'RDM')):
#         return 'DM'
#     elif ((df['club_position'] == 'LM') | (df['club_position'] == 'LCM') | (df['club_position'] == 'CM') | (df['club_position'] == 'RCM') | (df['club_position'] == 'RM')):
#         return 'MF'
#     elif ((df['club_position'] == 'LAM') | (df['club_position'] == 'CAM') | (df['club_position'] == 'RAM') | (df['club_position'] == 'LW') | (df['club_position'] == 'RW')):
#         return 'AM'
#     elif ((df['club_position'] == 'RS') | (df['club_position'] == 'ST') | (df['club_position'] == 'LS') | (df['club_position'] == 'CF') | (df['club_position'] == 'LF') | (df['club_position'] == 'RF')):
#         return 'ST'
#     else:
#         return df.club_position
# # print(type(x))
# x['club_position'] = x.apply(encode_club_position, axis = 1)
# # print(type(x['club_position']))
# x['club_position']=leave1out.fit_transform(x['club_position'],y)
#
# def encode_positions(position):
#    position = position[0]
#    if (position == 'GK'):
#         return 'pos_GK'
#    elif ((position == 'RB') | (position == 'LB') | (position == 'CB') | (position == 'LCB') | (position == 'RCB') | (position == 'RWB') | (position == 'LWB') ):
#       return 'pos_DF'
#    elif ((position == 'LDM') | (position == 'CDM') | (position == 'RDM')):
#       return 'pos_DM'
#    elif ((position == 'LM') | (position == 'LCM') | (position == 'CM') | (position == 'RCM') | (position == 'RM')):
#       return 'pos_MF'
#    elif ((position == 'LAM') | (position == 'CAM') | (position == 'RAM') | (position == 'LW') | (position == 'RW')):
#       return 'pos_AM'
#    elif ((position == 'RS') | (position == 'ST') | (position == 'LS') | (position == 'CF') | (position == 'LF') | (position == 'RF')):
#        return 'pos_ST'
#    else:
#        return 'pos_'+position
#
# first_pos = x['positions'].str.split(',', expand=True)[0]
# first_pos = pd.DataFrame(first_pos)
# x['positions'] = first_pos.apply(encode_positions, axis=1)
# # print(x['positions'])
# x = Feature_Encoder(x, ['positions'])
# # print(x['positions'])
#
# # Fill missing values
# # x.positions.fillna(x['positions'].mode()[0],inplace=True) #ZZZZZZZZZZ
# x.nationality.fillna(x.nationality.mode()[0],inplace=True)
# x.wage.fillna(x.wage.mean(),inplace=True)
# x.release_clause_euro.fillna(x.release_clause_euro.mean(),inplace=True)
# x.club_join_date.fillna(x.club_join_date.mode()[0],inplace=True)
# x.club_team.fillna(x.club_team.mode()[0],inplace=True)
# x.drop('club_team', axis=1, inplace=True) #ZZZZZZZZZZZZZ
#
# # Loops over all position columns and adds the bonuses to the original score & fills nulls with mean of result
# # Ex: 62+2 --> 64
# # Assume mean = 61: null --> 61
#
# for i in range(x.columns.get_loc('LS'),x.columns.get_loc('RB')+1):
#   x=x.astype({x.columns[i]:'str'})
#   x[x.columns[i]]=x[x.columns[i]].apply(lambda z: int(z.split('+',2)[0])+int(z.split('+',2)[1])if(z!='nan'and len(z)>2)else z)
#   x=x.astype({x.columns[i]:'float'})
#   x[x.columns[i]].fillna(x[x.columns[i]].mean(),inplace=True)
#   x=x.astype({x.columns[i]:'int'})
#   x=x.astype({x.columns[i]:'float'})
#
# # Scaling all features
# scaler=MinMaxScaler()
# # x=pd.DataFrame(scaler.fit_transform(x),columns=x.columns)
# #print(x.describe())
#
#
# def outlier(data,colName):
#   Q1,Q3=data[colName].quantile(0.25),data[colName].quantile(0.75)
#   IQR = Q3-Q1
#   lower =Q1-1.5*IQR
#   upper=Q3+1.5*IQR
#   return lower,upper
# print(x.shape)
# start_index = x.columns.get_loc('LWB')
# end_index = x.columns.get_loc('RB')
# x.drop(x.columns[start_index:end_index] , axis=1, inplace=True)
#
# to_drop = ['LS', 'ST', 'RS', 'LW', 'LF', 'CF', 'RF', 'RW', 'LAM', 'CAM', 'RAM', 'LM', 'LCM', 'CM', 'RM']
# x.drop(to_drop, axis=1, inplace=True)
#
# to_drop = ['GK_diving', 'GK_handling', 'GK_positioning', 'GK_reflexes']
# x.drop(to_drop, axis=1, inplace=True)
#
# x.columns
#
# to_drop = ['standing_tackle', 'sliding_tackle']
# x.drop(to_drop, axis=1, inplace=True)
#
# to_drop = ['ball_control','positioning','acceleration']
# x.drop(to_drop, axis=1, inplace=True)
# x.shape[1]
# print(x.shape)
#
# def outlier(data,colName):
#   Q1,Q3=data[colName].quantile(0.25),data[colName].quantile(0.75)
#   IQR = Q3-Q1
#   lower =Q1-1.5*IQR
#   upper=Q3+1.5*IQR
#   return lower,upper
#
# # tmp = pd.concat((x, y), axis=1)
# # print(tmp.shape)
#
# # corr =tmp.corr().abs()
# # plt.figure(figsize=(70,70))
# # sns.heatmap(corr, annot=True)
# # plt.show()
# # y= np.where(y==5,"S",np.where(y==4,"A",np.where(y==3,"B",np.where(y==2,"C","D"))))
# # y=pd.DataFrame(y)
from scipy.stats import chi2_contingency
from scipy.stats import chisquare
# # count=0
# # l=[]
# # ll=[]
# # for i in x:
# tmp = pd.concat((x, y), axis=1)
# #   statistic,p,dof,expected=chi2_contingency(tmp)
# #   print("------------------------------------------------------")
# #   print(i)
# #   print("statistic",statistic)
# #   print("p",p)
# #   print("dof",dof)
# #   # interpret test-statistic
# #   alpha = 0.05
# #   print("p value is " + str(p))
# #   if p <= alpha:
# #     ll.append(i)
# #     print('Dependent (reject H0)')
# #   else:
# #     count=count+1
# #     l.append(i)
# #     print('Independent (H0 holds true)')# have no relation
# # print(count)
# # print(l)
# # print(ll)
# data = pd.DataFrame(data=[(0 for i in range(len(tmp.columns))) for i in range(len(tmp.columns))],
#                          columns=list(tmp.columns))#2d matrix
# data.set_index(pd.Index(list(tmp.columns)), inplace = True)
l=[]
ll=[]
#Finding p_value for all columns and putting them in the resultant matrix
for i in list(tmp.columns):
     for j in list(tmp.columns):
         if i != j:
             chi2_val, p_val = chisquare(np.array(tmp[i]).reshape(-1, 1), np.array(tmp[j]).reshape(-1, 1))
             data.loc[i,j] = p_val
             if p_val>0.8:
               l.append((i,j))


#
print(data)
fig = plt.figure(figsize=(60,40))
sns.heatmap(data, annot=True, cmap='Blues')
plt.title('Chi-Square Test Results')
plt.show()
print(l)
print(len(l))
# #the matrix is symmetric so we need to extract upper triangle matrix without diagonal (k = 1)
# #and sort correlation values from higher to lower
# # sol = (corr.where(np.triu(np.ones(corr.shape), k=1).astype(np.bool))
# #                   .stack()
# #                   .sort_values(ascending=False))
#
#
# # Split data
# import time
# start_time = time.time()
# #best_test_error =  432896306883.1006
# #best_test_error =  1527621844424.3254
#
# xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=633)
#
# # Model
# lr=linear_model.LinearRegression()
# lr.fit(xtrain,ytrain)
#
# # Predictions
# ytp=lr.predict(xtrain)
# ypred=lr.predict(xtest)
#
#
#
#
#
# """Degree 2 model experiment"""
#
# print(y)
# print(x.work_rate_attack)
#
# print("--- %s seconds ---" , (time.time() - start_time))
# print('score',lr.score(xtest,ytest)*100)
# print('Train MSE: ',metrics.mean_squared_error(ytrain,ytp))
# print('Test MSE: ',metrics.mean_squared_error(ytest,ypred))
# #print('Best test MSE: ', best_test_error)
# print('Train R2 score: ', metrics.r2_score(ytrain,ytp))
# print('Test R2 score: ', metrics.r2_score(ytest,ypred))
# #print('Test R2 score: ', predicted_r2(ytest,ypred,xtest))
#
#
#
# start_time = time.time()
# xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=453,shuffle=True)
# m=PolynomialFeatures(degree=2)
# xp=m.fit_transform(xtrain)
# poly_model = linear_model.LinearRegression()
# poly_model.fit(xp, ytrain)
# y_train_predicted = poly_model.predict(xp)
# ypred=poly_model.predict(m.transform(xtest))
# # predicting on test data-set
# prediction = poly_model.predict(m.fit_transform(xtest))
#
# print("--- %s seconds ---" , (time.time() - start_time))
# #print('Best test MSE: ', best_test_error)
# print('score',poly_model.score(m.transform(xtest),ytest)*100)
# print('Train MSE: ',metrics.mean_squared_error(ytrain,y_train_predicted))
# print('Test MSE: ',metrics.mean_squared_error(ytest,prediction))
# print('Train R2 score: ', metrics.r2_score(ytrain,y_train_predicted))
# print('Test R2 score: ', metrics.r2_score(ytest,prediction))
# #print('Test R2 score: ', predicted_r2(ytest,prediction,xtest))
#
# # //////////
# # --- %s seconds --- 2.801224946975708
# # score 98.56543001880144
# # Train MSE:  267734585524.83347
# # Test MSE:  297091704161.9996
# # Train R2 score:  0.9924552264679536
# # Test R2 score:  0.9856543001880144
#
# from sklearn import tree
# from sklearn.metrics import confusion_matrix
# from sklearn.metrics import multilabel_confusion_matrix
#
# xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=453,shuffle=True)
# clf = tree.DecisionTreeClassifier(random_state=1334,ccp_alpha=0.000001,)
# clf.fit(xtrain , ytrain)
# ypred=clf.predict(xtest)
# print(clf.feature_importances_)
# print("train",clf.score(xtrain,ytrain))
# print("test",clf.score(xtest,ytest))
# print(metrics.f1_score(ytest,ypred, pos_label='positive',average='micro'))
# print(multilabel_confusion_matrix(ytest,ypred))
# confusion_matrix(ytest,ypred)
# # import joblib
#
# # joblib.dump(clf, "tree_random_state=1334.pkl")
#
# C = 1.3 # SVM regularization parameter
# svc = svm.SVC(kernel='rbf', C=C)
# s=OneVsOneClassifier(svc).fit(xtrain, ytrain)
# print("--------------------------")
# print(i)
# print('training',s.score(xtrain,ytrain))
# print('testing',s.score(xtest,ytest))
#
#
# # import joblib
#
# # joblib.dump(svc, "SVM(rbf_oneVSone).pkl")
# # training 0.811190053285968
# # testing 0.8121448863636364
#
# predictions = svc.predict(xtest)
# # accuracy = np.mean(predictions == ytest)
# # print('Testing accuracy :', accuracy)
# # print('-----------------------------')
# print(svc.score(xtest,ytest))
#
# from sklearn.linear_model import LogisticRegression
# logistic=LogisticRegression()
# s=OneVsOneClassifier(logistic).fit(xtrain, ytrain)
#
# print(s.score(xtrain,ytrain))
# print(s.score(xtest,ytest))
#
# import joblib
#
# # joblib.dump(svc, "Logistic.pkl")

for i in x.columns.values: 
  print(i)
  if i not in ToSaveList.keys():
     ToSaveList[i]=x[i].mean()

#joblib.dump(ToSaveList, "ToSaveList.pkl")

